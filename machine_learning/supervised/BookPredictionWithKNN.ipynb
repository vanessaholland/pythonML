{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different approach to book recommendations using KNN (K-Nearest-Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the heavy lift here was getting the book data combined and cleaned. Leaving the steps here for future self: \n",
    "get the previously cleaned data with book_id, title, rating, and user_id fields\n",
    "```\n",
    "ratings = pd.read_csv(\"../../datasets/Book_ratings_clean.csv\")\n",
    "ratings.head()\n",
    "\n",
    "id\tbook_id\ttitle\trating\tuser_id\n",
    "0\t10\t0829814000\tWonderful Worship in Smaller Churches\t19.40\tAZ0IOBU20TBOP\n",
    "1\t11\t0829814000\tWonderful Worship in Smaller Churches\t19.40\tA373VVEU6Z9M0N\n",
    "2\t12\t0829814000\tWonderful Worship in Smaller Churches\t19.40\tAGKGOH65VTRR4\n",
    "3\t13\t0829814000\tWonderful Worship in Smaller Churches\t19.40\tA3OQWLU31BU1Y\n",
    "4\t14\t0595344550\tWhispers of the Wicked Saints\t10.95\tA3Q12RK71N74LB\n",
    "\n",
    "```\n",
    "the problem with this data is that it doesn't have the book metadata. Problem with the metadata is that it doesn't contain the book_id, so you have to match it on title. Not too bad. \n",
    "```\n",
    "book_ids_titles = ratings[['book_id', 'title']]\n",
    "book_ids_titles = book_ids_titles.drop_duplicates()\n",
    "\n",
    "bookMetaData = pd.read_csv(\"../../datasets/books_data.csv\")\n",
    "bookMetaData.drop_duplicates()\n",
    "bookMetaData.rename(columns={'Title':'title'}, inplace=True)\n",
    "\n",
    "bookMetaData = bookMetaData.merge(book_ids_titles.set_index('title'), how='left', on='title')\n",
    "bookMetaData = bookMetaData.dropna(subset=['book_id'])\n",
    "bookMetaData.head()\n",
    "bookMetaData.to_csv('../datasets/book_metadata_with_ids.csv')\n",
    "```\n",
    "\n",
    "Once you do that you need to aggregate all the ratings so that you get the total ratings size and mean. \n",
    "```\n",
    "bookRatings = ratings.groupby('book_id').agg({'rating': [np.size, np.mean]})\n",
    "bookRatings.head()\n",
    "\n",
    "\trating\n",
    "size\tmean\n",
    "book_id\t\t\n",
    "0002554232\t3\t24.32\n",
    "0004332466\t1\t8.95\n",
    "0005993814\t1\t35.00\n",
    "0006482724\t1\t13.99\n",
    "0007104022\t1\t18.99\n",
    "\n",
    "bookNumRatings = pd.DataFrame(bookRatings['rating']['size'])\n",
    "bookMeanRatings = pd.DataFrame(bookRatings['rating']['mean'])\n",
    "bookNormalizedNumRatings = bookNumRatings.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "bookNormalizedNumRatings.head()\n",
    "\n",
    "\tsize\n",
    "book_id\t\n",
    "0002554232\t0.001369\n",
    "0004332466\t0.000000\n",
    "0005993814\t0.000000\n",
    "0006482724\t0.000000\n",
    "0007104022\t0.000000\n",
    "\n",
    "bookMetaData = bookMetaData.merge(bookNormalizedNumRatings, how='left', on='book_id') \n",
    "bookMetaData = bookMetaData.merge(bookMeanRatings, how='left', on='book_id')  \n",
    "\n",
    "```\n",
    "Next pull out only the relevant data into it's own dataframe to export it to csv so you don't need to do this again. \n",
    "```\n",
    "focusedBookData = bookMetaData[['book_id', 'title', 'size', 'mean', 'authors', 'publisher', 'publishedDate', 'categories']]\n",
    "focusedBookData.to_csv('../../datasets/focused_book_meta_data_clean.csv')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>19.40</td>\n",
       "      <td>['David R. Ray']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>['Religion']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0595344550</td>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>10.95</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>2005-02</td>\n",
       "      <td>['Fiction']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0253338352</td>\n",
       "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.95</td>\n",
       "      <td>['Edward Long']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-03-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0802841899</td>\n",
       "      <td>The Church of Christ: A Biblical Ecclesiology ...</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>25.97</td>\n",
       "      <td>['Everett Ferguson']</td>\n",
       "      <td>Wm. B. Eerdmans Publishing</td>\n",
       "      <td>1996</td>\n",
       "      <td>['Religion']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0895554224</td>\n",
       "      <td>Saint Hyacinth of Poland</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.95</td>\n",
       "      <td>['Mary Fabyan Windeatt']</td>\n",
       "      <td>Tan Books &amp; Pub</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     book_id                                              title  \\\n",
       "0           0  0829814000              Wonderful Worship in Smaller Churches   \n",
       "1           1  0595344550                      Whispers of the Wicked Saints   \n",
       "2           2  0253338352  Nation Dance: Religion, Identity and Cultural ...   \n",
       "3           3  0802841899  The Church of Christ: A Biblical Ecclesiology ...   \n",
       "4           4  0895554224                           Saint Hyacinth of Poland   \n",
       "\n",
       "       size   mean                   authors                   publisher  \\\n",
       "0  0.002053  19.40          ['David R. Ray']                         NaN   \n",
       "1  0.021218  10.95       ['Veronica Haddon']                   iUniverse   \n",
       "2  0.000000  39.95           ['Edward Long']                         NaN   \n",
       "3  0.002053  25.97      ['Everett Ferguson']  Wm. B. Eerdmans Publishing   \n",
       "4  0.000000  13.95  ['Mary Fabyan Windeatt']             Tan Books & Pub   \n",
       "\n",
       "  publishedDate                     categories  \n",
       "0          2000                   ['Religion']  \n",
       "1       2005-02                    ['Fiction']  \n",
       "2    2003-03-01                            NaN  \n",
       "3          1996                   ['Religion']  \n",
       "4    2009-01-01  ['Biography & Autobiography']  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"../../datasets/focused_book_meta_data_clean.csv\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with this focused data containing 47,984 rows, cast it to a dict to work with for the rest of this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to compute the distance between two books based on how similar there categories are, and their mean rating, need to convert the categorical categories into numerical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['Religion']\" \"['Fiction']\" nan ... \"['Agricultural diversification']\"\n",
      " \"['Arthur']\" \"['Colombo (Sri Lanka)']\"]\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "categories = ratings.categories.unique()\n",
    "print(categories)\n",
    "print(len(categories))\n",
    "cat_dict = {}\n",
    "i = 0\n",
    "for category in categories:\n",
    "    cat_dict[category] = [i]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['categories'] = ratings['categories'].map(cat_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further improvements for later: find the unique categories by splitting on '&', for example: `['Biography & Autobiography']` would become an array of say `[1, 2]`. This way something like `[Science Fiction & Historical Fiction]` could be compared with books that are strictly `Science Fiction` and `Historical Fiction`. \n",
    "Another potential improvement would be to cast authors to numerical data too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# being more explicit with the name here\n",
    "ratings.rename(columns={'size':'ratingSize'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_dict = {}\n",
    "for index, row in ratings.iterrows():\n",
    "    book_dict[row['book_id']] = (row['title'], row['ratingSize'], row['mean'], row['authors'], row['publisher'], row['publishedDate'], row['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Saint Hyacinth of Poland',\n",
       " 0.0,\n",
       " 13.95,\n",
       " \"['Mary Fabyan Windeatt']\",\n",
       " 'Tan Books & Pub',\n",
       " '2009-01-01',\n",
       " [3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_dict['0895554224']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, following the tutorial for KNN, compute the distance between two given books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4038329911019849"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def ComputeDistance(a, b):\n",
    "    categoriesA = a[6]\n",
    "    categoriesB = b[6]\n",
    "    genreDistance = spatial.distance.cosine(categoriesA, categoriesB)\n",
    "    popularityA = a[1]\n",
    "    popularityB = b[1]\n",
    "    popularityDistance = abs(popularityA - popularityB)\n",
    "    return genreDistance + popularityDistance\n",
    "    \n",
    "ComputeDistance(book_dict['1594567263'], book_dict['0891010947'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the distance, the less similar the books are. A classic fiction book vs a book on The Civil War are subjectively very different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Picture of Dorian Gray', 0.4045174537987679, 26.0, \"['Óscar Wilde']\", nan, '2016-01-24', [2])\n",
      "('The Civil War Recollections of General Ellis Spear', 0.000684462696783, 28.0, \"['Ellis Spear']\", nan, '1997', [8])\n"
     ]
    }
   ],
   "source": [
    "print(book_dict['0939495805'])\n",
    "print(book_dict['0891010947'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, following the tutorial, compute the distance between the given book and all of the books in the data set. Sort those by distance, and print out the K nearest neighbors. Compare this list with the list generated by the previous attempt at `/MachineLearning/BookPrediction.ipynb`\n",
    "\n",
    "```\n",
    "Alice's Adventures in Wonderland and Through the Looking Glass (Classic Collection (Brilliance Audio))    1.000\n",
    "The Picture of Dorian Gray                                                                                1.000\n",
    "The Red Badge of Courage (Lake Illustrated Classics, Collection 1)                                        1.000\n",
    "Wuthering Heights                                                                                         1.000\n",
    "the Picture of Dorian Gray                                                                                1.000\n",
    "A Christmas Carol (Classic Fiction)                                                                       1.000\n",
    "A Christmas Carol, in Prose: Being a Ghost Story of Christmas (Collected Works of Charles Dickens)        1.000\n",
    "The Picture of Dorian Gray (The Classic Collection)                                                       0.998\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1557424470', '1594567263', '1597370037', '1597370045', '1597370061', '0679766758', '0748608370', '0895260786', '0785263705', '0808598104']\n",
      "The Picture of Dorian Gray 18.96\n",
      "the Picture of Dorian Gray 12.99\n",
      "The Picture of Dorian Gray (The Classic Collection) 25.04\n",
      "The Picture of Dorian Gray (Classic Collection (Brilliance Audio)) 87.25\n",
      "The Picture of Dorian Gray (Classic Collection (Brilliance Audio)) 39.25\n",
      "Push: A Novel 7.06\n",
      "Treasure Island 54.0\n",
      "America Alone: The End of the World as We Know It 18.46\n",
      "Blue Like Jazz: Nonreligious Thoughts on Christian Spirituality 11.35\n",
      "The Killer Angels (Turtleback School & Library Binding Edition) 13.8\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "def getNeighbors(bookID, K):\n",
    "    distances = []\n",
    "    for book in book_dict:\n",
    "        if (book != bookID):\n",
    "            dist = ComputeDistance(book_dict[bookID], book_dict[book])\n",
    "            distances.append((book, dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(K):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "K = 10\n",
    "avgRating = 0\n",
    "neighbors = getNeighbors('0939495805', K)\n",
    "print(neighbors)\n",
    "for neighbor in neighbors:\n",
    "    avgRating += book_dict[neighbor][2]\n",
    "    print (book_dict[neighbor][0] + \" \" + str(book_dict[neighbor][2]))\n",
    "    \n",
    "avgRating /= K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely some different selections this way. Subjectively, I as a user would be happier with the previous recommendations. While we were at it, we computed the average rating of the 10 nearest neighbors to the selected book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.816000000000003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgRating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with actual rating mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The Picture of Dorian Gray',\n",
       " 0.4045174537987679,\n",
       " 26.0,\n",
       " \"['Óscar Wilde']\",\n",
       " nan,\n",
       " '2016-01-24',\n",
       " [2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_dict['0939495805']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could be better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching to Rating Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to see if that has any impact on selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1557424470', '1594567263', '1597370037', '1597370045', '1597370061', '0679766758', '0748608370', '0895260786', '0785263705', '0808598104']\n",
      "The Picture of Dorian Gray 0.4045174537987679\n",
      "the Picture of Dorian Gray 0.4045174537987679\n",
      "The Picture of Dorian Gray (The Classic Collection) 0.4045174537987679\n",
      "The Picture of Dorian Gray (Classic Collection (Brilliance Audio)) 0.4045174537987679\n",
      "The Picture of Dorian Gray (Classic Collection (Brilliance Audio)) 0.4045174537987679\n",
      "Push: A Novel 0.4045174537987679\n",
      "Treasure Island 0.4024640657084189\n",
      "America Alone: The End of the World as We Know It 0.4106776180698152\n",
      "Blue Like Jazz: Nonreligious Thoughts on Christian Spirituality 0.4223134839151266\n",
      "The Killer Angels (Turtleback School & Library Binding Edition) 0.4229979466119096\n"
     ]
    }
   ],
   "source": [
    "def getNeighbors(bookID, K):\n",
    "    distances = []\n",
    "    for book in book_dict:\n",
    "        if (book != bookID):\n",
    "            dist = ComputeDistance(book_dict[bookID], book_dict[book])\n",
    "            distances.append((book, dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(K):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "K = 10\n",
    "avgRating = 0\n",
    "neighbors = getNeighbors('0939495805', K)\n",
    "print(neighbors)\n",
    "for neighbor in neighbors:\n",
    "    avgRating += book_dict[neighbor][1]\n",
    "    print (book_dict[neighbor][0] + \" \" + str(book_dict[neighbor][1]))\n",
    "    \n",
    "avgRating /= K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further testing that can be done: \n",
    "Choice of 10 for K was arbitrary - what effect do different K values have on the results?\n",
    "\n",
    "Distance metric was also somewhat arbitrary - just took the cosine distance between the genres and added it to the difference between the normalized popularity scores. Can that be improved? Dive further into spacial.distance used in ComputeDistance method to look for improvements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
